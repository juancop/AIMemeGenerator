{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "# Para eliminar palabrotas\n",
    "import spanlp\n",
    "from spanlp.palabrota import Palabrota\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/daniel/Documents/GitHub/AIMemeGenerator/data/scrapper'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta de archivos a procesar\n",
    "path_original = '/home/daniel/Documents/GitHub/AIMemeGenerator'\n",
    "#path_original = os.getcwd()\n",
    "path = path_original + '/data/scrapper'\n",
    "os.chdir(path)\n",
    "os.getcwd()\n",
    "# ruta de directorio a crear\n",
    "#path_bases_no_tildes = path_original + \"/data/bases_no_tildes\"\n",
    "#os.makedirs(path_bases_no_tildes,0o007)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n",
    "files = [val for val in files if re.search(r'.csv\\Z', val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: scrapymemes14m.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "registros sin limpieza: 1028\n",
      "Expresiones sin limpiar: 1455\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Parámetros: Campos para reemplazar tildes\n",
    "x = \"aaaaaaeeeeiiiioooooouuuuy\"       # Tildes\n",
    "y = \"àáâãäåèéêëìíîïðòóôõöùúûüý\"       # Caradteres que no fueron identificados por utf-8\n",
    "char_replace = {'ñ':'n','Ñ':'N','Ã“':\"O\", 'Ã‘':'O','Ã­':'I',\n",
    "                'Ã‰':'E','Ãš':'U','â™':'u','âˆ':'e','ÃŒ':'I',\n",
    "                'Ãˆ':'E','Ãš':'U','â€':'A','Ã±':'n','Ã':'A'}\n",
    "\n",
    "\n",
    "# groserias\n",
    "\n",
    "\n",
    "# Objetos\n",
    "sin_convertir = {}     # Guardará índices de filas que no se pudieron convertir.\n",
    "word_list     = []     # Listado de caracteres\n",
    "rows_to_drop  = [' Personalizado','plantilla']\n",
    "list_print    = np.arange(0,1000000,10000)\n",
    "\n",
    "for file in files:\n",
    "    print(\"Archivo:\",file)\n",
    "    file_name = re.sub('\\.csv$', '', file) \n",
    "    # Cargar archivos:\n",
    "    base = pd.read_csv(\"./\"+file,encoding=\"utf-8\")                            # Cargar archivo\n",
    "    base.drop_duplicates(subset=['plantilla','texto'],inplace=True,ignore_index=True) # Eliminar duplicados\n",
    "    base = base[~base.plantilla.isin(rows_to_drop)]\n",
    "    base[\"texto_no_tilde\"] = \"\"                                           # Crear campo de texto para almacenar tildes\n",
    "    id_no_encode = []                                                     # Lista para almacenar code_id     \n",
    "\n",
    "    index = 0            # índice en cero para iterar por filas\n",
    "    # Loop para convertir caracteres de latin-1 a utf-8 y guardar información en nueva tabla\n",
    "    for t in base.texto:\n",
    "        if index in list_print:\n",
    "            print(index)\n",
    "        try:\n",
    "            for a,b in char_replace.items():\n",
    "              t = t.replace(a,b)\n",
    "            tab_map = t.maketrans(y, x)\n",
    "            t = t.translate(tab_map).strip()\n",
    "            t =  t.encode(\"latin-1\").decode(\"utf-8\")\n",
    "            t = t.translate(tab_map).strip()\n",
    "            base.iat[index,base.columns.get_loc('texto_no_tilde')] = t\n",
    "            index += 1\n",
    "         # Si no logra convertir un caracter, guardar el índice dentro de la base y continuar.    \n",
    "        except UnicodeEncodeError:\n",
    "            id_no_encode.append(index)\n",
    "            index += 1\n",
    "            array = t.split() \n",
    "            for k in array:\n",
    "                try:\n",
    "                    k.encode(\"latin-1\").decode(\"utf-8\")\n",
    "                except:\n",
    "                    word_list.append(k)\n",
    "                pass\n",
    "            pass\n",
    "        except UnicodeDecodeError:\n",
    "            id_no_encode.append(index)\n",
    "            index += 1\n",
    "            array = t.split() \n",
    "            for k in array:\n",
    "                try:\n",
    "                    k.encode(\"latin-1\").decode(\"utf-8\")\n",
    "                except:\n",
    "                    word_list.append(k)\n",
    "                pass\n",
    "            pass        \n",
    "    # Guardar archivos limpios\n",
    "    base = base[base[\"texto_no_tilde\"] != \"\"]\n",
    "    str_file = path_original + \"/data/bases_no_tilde/\" + file_name + \"_no_tilde.csv\"\n",
    "    base.to_csv(str_file, index=False )\n",
    "    # Guardar índices\n",
    "    sin_convertir[file_name] = id_no_encode\n",
    "    print(\"registros sin limpieza:\",len(id_no_encode))\n",
    "    print(\"Expresiones sin limpiar:\",len(word_list))\n",
    "    print(\" \")\n",
    "word_list = list(dict.fromkeys(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scrapymemes14m.csv',\n",
       " 'scrapymemes8m.csv',\n",
       " 'scrapymemes23m.csv',\n",
       " 'scrapymemes7m.csv',\n",
       " 'scrapymemes17m.csv',\n",
       " 'scrapymemes25m.csv',\n",
       " 'scrapymemes3m.csv',\n",
       " 'scrapymemes33m.csv',\n",
       " 'scrapymemes27m.csv',\n",
       " 'scrapymemes15m.csv',\n",
       " 'scrapymemes16m.csv',\n",
       " 'scrapymemes11m.csv',\n",
       " 'scrapymemes10m.csv',\n",
       " 'scrapymemes32m.csv',\n",
       " 'scrapymemes2m.csv',\n",
       " 'scrapymemes19m.csv',\n",
       " 'scrapymemes6m.csv',\n",
       " 'scrapymemes5m.csv',\n",
       " 'scrapymemes28m.csv',\n",
       " 'scrapymemes9m.csv',\n",
       " 'scrapymemes29m.csv',\n",
       " 'scrapymemes22m.csv',\n",
       " 'scrapymemes30m.csv',\n",
       " 'scrapymemes2mp2.csv',\n",
       " 'scrapymemes21m.csv',\n",
       " 'scrapymemes18m.csv',\n",
       " 'scrapymemes24m.csv',\n",
       " 'scrapymemes26m.csv',\n",
       " 'scrapymemes4m.csv',\n",
       " 'scrapymemes1m.csv',\n",
       " 'scrapymemes20m.csv',\n",
       " 'scrapymemes31m.csv',\n",
       " 'scrapymemes12m.csv',\n",
       " 'scrapymemes13m.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
