{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "# Para eliminar palabrotas\n",
    "import spanlp\n",
    "#from spanlp.palabrota import Palabrota\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/daniel/Documents/GitHub/AIMemeGenerator/data/scrapper'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta de archivos a procesar\n",
    "path_original = '/home/daniel/Documents/GitHub/AIMemeGenerator'\n",
    "#path_original = os.getcwd()\n",
    "path = path_original + '/data/scrapper'\n",
    "os.chdir(path)\n",
    "os.getcwd()\n",
    "# ruta de directorio a crear\n",
    "#path_bases_no_tildes = path_original + \"/data/bases_no_tildes\"\n",
    "#os.makedirs(path_bases_no_tildes,0o007)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n",
    "files = [val for val in files if re.search(r'.csv\\Z', val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [#['scrapymemes10m.csv',\n",
    "#'scrapymemes33m.csv',\n",
    "#'scrapymemes9m.csv',\n",
    "#'scrapymemes11m.csv',\n",
    "#'scrapymemes12m.csv',\n",
    "#'scrapymemes22m.csv',\n",
    "#'scrapymemes2mp2.csv',\n",
    "#'scrapymemes17m.csv',\n",
    "#'scrapymemes18m.csv',\n",
    "'scrapymemes25m.csv',\n",
    "'scrapymemes13m.csv',\n",
    "'scrapymemes21m.csv',\n",
    "'scrapymemes26m.csv',\n",
    "'scrapymemes7m.csv',\n",
    "'scrapymemes20m.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scrapymemes25m.csv',\n",
       " 'scrapymemes13m.csv',\n",
       " 'scrapymemes21m.csv',\n",
       " 'scrapymemes26m.csv',\n",
       " 'scrapymemes7m.csv',\n",
       " 'scrapymemes20m.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: scrapymemes25m.csv\n",
      "Cantidad de registros: 237157\n",
      " \n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      " \n",
      "Archivo: scrapymemes13m.csv\n",
      "Cantidad de registros: 253279\n",
      " \n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      " \n",
      "Archivo: scrapymemes21m.csv\n",
      "Cantidad de registros: 253833\n",
      " \n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      " \n",
      "Archivo: scrapymemes26m.csv\n",
      "Cantidad de registros: 231766\n",
      " \n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      " \n",
      "Archivo: scrapymemes7m.csv\n",
      "Cantidad de registros: 340502\n",
      " \n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n"
     ]
    }
   ],
   "source": [
    "# Parámetros: Campos para reemplazar tildes\n",
    "x = \"aaaaaaeeeeiiiioooooouuuuy\"       # Tildes\n",
    "y = \"àáâãäåèéêëìíîïðòóôõöùúûüý\"       # Caradteres que no fueron identificados por utf-8\n",
    "char_replace = {'Ã“':\"O\", 'Ã‘':'O','Ã­':'I',\n",
    "                'Ã‰':'E','Ãš':'U','â™':'u','âˆ':'e','ÃŒ':'I',\n",
    "                'Ãˆ':'E','Ãš':'U','â€':'A','Ã':'A','Ã±':'n','Ã‘':'ñ'}\n",
    "#files=  files[0]\n",
    "\n",
    "exceptions = [\"ano\",\"pendejo\",\"pendeja\",\"estupido\",\"estupida\",\"joder\",\"tonto\",\"tonta\",\"pete\",\"marinero\",\"bobo\",\n",
    "             \"perro\",\"idiotas\",\"idiota\",\"computadora\",\"joda\",\"dios\",\"jodas\",\"jode\",\"la computadora\",\n",
    "              \"imbecil\",\"pagan\",\"paja\",\"paga\",\"ojo\",\"internet\",\"rata\",\"baboso\",\"bochinche\",\"boletoso\",\n",
    "             \"bombril\",\"cachon\",\"guiso\",\"hoyo\",\"jartera\",\"lampara\",\"lamparoso\",\"lichigo\",\"mamera\",\"orto\",\n",
    "             \"tontarron\",\"cojones\",\"globalizacion\"]\n",
    "\n",
    "include_words = [\"verga\",\"culaso\",\"maricon\",\"marico\",\"putear\",\"putona\",\"puti\",\"putita\"]\n",
    "\n",
    "\n",
    "# groserias\n",
    "from spanlp.palabrota import Palabrota\n",
    "from spanlp.domain.strategies import CosineSimilarity\n",
    "from spanlp.domain.strategies import JaccardIndex\n",
    "\n",
    "# Limpieza de texto\n",
    "from spanlp.domain.strategies import Preprocessing, TextToLower, NumbersToVowelsInLowerCase ,NumbersToConsonantsInLowerCase, ExpandAbbreviations\n",
    "from spanlp.domain.countries import Country\n",
    "\n",
    "#strategies = [TextToLower(), NumbersToVowelsInLowerCase(), \n",
    "#             NumbersToConsonantsInLowerCase(), ExpandAbbreviations()] # Defino mis estrategias de limpieza o pre-procesamiento\n",
    "\n",
    "#cosine = CosineSimilarity(0.95, normalize=False) \n",
    "#jaccard = JaccardIndex(threshold=0.95, normalize=False, n_gram=2)\n",
    "palabrota = Palabrota(countries=[Country.COLOMBIA,Country.ESPANA, Country.ARGENTINA], exclude=exceptions, \n",
    "                       include=include_words) #,\n",
    "#                     distance_metric=cosine)\n",
    "\n",
    "\n",
    "# Objetos\n",
    "sin_convertir = {}     # Guardará índices de filas que no se pudieron convertir o de groserías.\n",
    "word_list     = []     # Listado de caracteres\n",
    "rows_to_drop  = [' Personalizado','plantilla']\n",
    "list_print    = np.arange(0,1000000,10000)\n",
    "\n",
    "for file in files:\n",
    "    print(\"Archivo:\",file)\n",
    "    file_name = re.sub('\\.csv$', '', file) \n",
    "    # Cargar archivos:\n",
    "    base = pd.read_csv(\"./\"+file,encoding=\"utf-8\")                            # Cargar archivo\n",
    "    base.drop_duplicates(subset=['plantilla','texto'],inplace=True,ignore_index=True) # Eliminar duplicados\n",
    "    base = base[~base.plantilla.isin(rows_to_drop)]\n",
    "    base[\"texto_no_tilde\"] = \"\"                                           # Crear campo de texto para almacenar tildes\n",
    "    base[\"palabrota\"]     = \"\"\n",
    "    id_no_encode = []                                                     # Lista para almacenar code_id     \n",
    "\n",
    "    print(\"Cantidad de registros:\",base.shape[0])\n",
    "    print(\" \")\n",
    "    index = 0            # índice en cero para iterar por filas\n",
    "    # Loop para convertir caracteres de latin-1 a utf-8 y guardar información en nueva tabla\n",
    "    for t in base.texto:\n",
    "    #for index in range(0,base.shape[0]):\n",
    "        if index in list_print:\n",
    "            print(index)\n",
    "        try:\n",
    "            #t = base.values[index,2]\n",
    "            #t = base.iat[index,2]\n",
    "            tab_map = t.maketrans(y, x)\n",
    "            t = t.translate(tab_map).strip()\n",
    "            t =  t.encode(\"latin-1\").decode(\"utf-8\")\n",
    "            for a,b in char_replace.items():\n",
    "                t = t.replace(a,b)\n",
    "            t = t.translate(tab_map).strip()\n",
    "            #base.values[index,3] = t\n",
    "            base.iat[index,3] = t\n",
    "            # Filtro de groserías\n",
    "            base.iat[index,4] = palabrota.contains_palabrota(t)\n",
    "            #base.values[index,4] = palabrota.contains_palabrota(t)\n",
    "            index += 1\n",
    "        # Si no logra convertir un caracter, guardar el índice dentro de la base y continuar.    \n",
    "        except UnicodeEncodeError:\n",
    "            id_no_encode.append(index)\n",
    "            index += 1\n",
    "       #     array = t.split() \n",
    "       #     for k in array:\n",
    "       #         try:\n",
    "       #             k.encode(\"latin-1\").decode(\"utf-8\")\n",
    "       #         except:\n",
    "       #             word_list.append(k)\n",
    "       #         pass\n",
    "       #     pass\n",
    "        except UnicodeDecodeError:\n",
    "            id_no_encode.append(index)\n",
    "            index += 1\n",
    "       #     array = t.split() \n",
    "       #     for k in array:\n",
    "       #         try:\n",
    "       #             k.encode(\"latin-1\").decode(\"utf-8\")\n",
    "       #         except:\n",
    "       #             word_list.append(k)\n",
    "       #         pass\n",
    "       #     pass        \n",
    "    # Guardar archivos limpios\n",
    "    base = base[base[\"texto_no_tilde\"] != \"\"]\n",
    "    #base = base[base[\"palabrota\"]==False]\n",
    "    base = base[base.palabrota == 0]\n",
    "    str_file = path_original + \"/data/bases_no_groserias/\" + file_name + \"_no_tilde.csv\"\n",
    "    base.to_csv(str_file, index=False )\n",
    "    del base, index, id_no_encode\n",
    "    # Guardar índices\n",
    "  #  sin_convertir[file_name] = id_no_encode\n",
    "   # print(\"registros sin limpieza:\",len(id_no_encode))\n",
    "    # print(\"Expresiones sin limpiar:\",len(word_list))\n",
    "    print(\" \")\n",
    "# word_list = list(dict.fromkeys(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>plantilla</th>\n",
       "      <th>texto</th>\n",
       "      <th>texto_no_tilde</th>\n",
       "      <th>palabrota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24000001</td>\n",
       "      <td>Correction Guy</td>\n",
       "      <td>please Bitch vuelve a queen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24000005</td>\n",
       "      <td>Correction Guy</td>\n",
       "      <td>please Bitch vuelve a queens</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24000002</td>\n",
       "      <td>Futurama Fry</td>\n",
       "      <td>cuando te das cuenta que no tienes amigos</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24000004</td>\n",
       "      <td>Skeptical 3rd World Kid</td>\n",
       "      <td>eres politica? por que si lo eres ve a robar ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24000000</td>\n",
       "      <td>Batman slaps Robin</td>\n",
       "      <td>Puta PerrA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339648</th>\n",
       "      <td>24999978</td>\n",
       "      <td>Desk Flip Rage Guy</td>\n",
       "      <td>me bale berga la vidaaaaaÂ¡Â¡Â¡Â¡</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339649</th>\n",
       "      <td>24999979</td>\n",
       "      <td>fat chinese kid</td>\n",
       "      <td>Oscar G. , Quiero mi jamÃ³n...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339650</th>\n",
       "      <td>24999987</td>\n",
       "      <td>I Hate</td>\n",
       "      <td>cuando alexandra te sonrie</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339652</th>\n",
       "      <td>24999991</td>\n",
       "      <td>crying peter parker</td>\n",
       "      <td>Dilson no me voy a salir Palma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339653</th>\n",
       "      <td>24999995</td>\n",
       "      <td>Homer</td>\n",
       "      <td>Looolas mmmmm</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237157 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                  plantilla  \\\n",
       "1       24000001            Correction Guy   \n",
       "2       24000005            Correction Guy   \n",
       "3       24000002              Futurama Fry   \n",
       "4       24000004   Skeptical 3rd World Kid   \n",
       "5       24000000        Batman slaps Robin   \n",
       "...          ...                       ...   \n",
       "339648  24999978        Desk Flip Rage Guy   \n",
       "339649  24999979           fat chinese kid   \n",
       "339650  24999987                    I Hate   \n",
       "339652  24999991       crying peter parker   \n",
       "339653  24999995                     Homer   \n",
       "\n",
       "                                                    texto texto_no_tilde  \\\n",
       "1                            please Bitch vuelve a queen                   \n",
       "2                           please Bitch vuelve a queens                   \n",
       "3              cuando te das cuenta que no tienes amigos                   \n",
       "4        eres politica? por que si lo eres ve a robar ...                  \n",
       "5                                             Puta PerrA                   \n",
       "...                                                   ...            ...   \n",
       "339648                me bale berga la vidaaaaaÂ¡Â¡Â¡Â¡                    \n",
       "339649                    Oscar G. , Quiero mi jamÃ³n...                   \n",
       "339650                       cuando alexandra te sonrie                    \n",
       "339652                    Dilson no me voy a salir Palma                   \n",
       "339653                                     Looolas mmmmm                   \n",
       "\n",
       "       palabrota  \n",
       "1                 \n",
       "2                 \n",
       "3                 \n",
       "4                 \n",
       "5                 \n",
       "...          ...  \n",
       "339648            \n",
       "339649            \n",
       "339650            \n",
       "339652            \n",
       "339653            \n",
       "\n",
       "[237157 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
