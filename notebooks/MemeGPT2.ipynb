{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# GPT-2 Using HuggingFance and Tensorflow\n",
    "En este Notebook se realizarán los procesamientos necesarios para hacer fine tuning de GPT-2 para la generación de memes en español.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Carga de Información\n",
    "Durante la primera fase de creación, se utilizará únicamente uno de los conjuntos de datos disponibles. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bases_no_tilde/useful_scrapymemes1m_no_tilde.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(~df.text_1.isna()) & (~df.text_2.isna())]\n",
    "df[\"text_1\"] = df[\"text_1\"].str.lower()\n",
    "df[\"text_2\"] = df[\"text_2\"].str.lower()\n",
    "df['meme_id'] = df['meme_id'].apply('{:0>4}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0 meme_id     plantilla  \\\n",
       "0           4    0007  Futurama Fry   \n",
       "1          13    0007  Futurama Fry   \n",
       "3          46    0003         Ay Si   \n",
       "4          50    0012   Willy Wonka   \n",
       "5          51    0007  Futurama Fry   \n",
       "\n",
       "                                      texto_no_tilde  \\\n",
       "0    no se si cortarme las venas o dejarmelas largas   \n",
       "1     no se si estudiar control o estudiar elementos   \n",
       "3                 ay si me pongo copete y ya soy emo   \n",
       "4  ¿conque eres regaytonero?... !!dime que se sie...   \n",
       "5  nO estoy seguro si nadie se levanta temprano o...   \n",
       "\n",
       "                                         text_1  \\\n",
       "0                   no se si cortarme las venas   \n",
       "1                     no se si estudiar control   \n",
       "3                                         ay si   \n",
       "4               ¿conque eres regaytonero?... !!   \n",
       "5  no estoy seguro si nadie se levanta temprano   \n",
       "\n",
       "                                   text_2  \n",
       "0                     o dejarmelas largas  \n",
       "1                    o estudiar elementos  \n",
       "3            me pongo copete y ya soy emo  \n",
       "4  dime que se siente cagar por la boca..  \n",
       "5      o no saben que entra en el control  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>meme_id</th>\n      <th>plantilla</th>\n      <th>texto_no_tilde</th>\n      <th>text_1</th>\n      <th>text_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>0007</td>\n      <td>Futurama Fry</td>\n      <td>no se si cortarme las venas o dejarmelas largas</td>\n      <td>no se si cortarme las venas</td>\n      <td>o dejarmelas largas</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13</td>\n      <td>0007</td>\n      <td>Futurama Fry</td>\n      <td>no se si estudiar control o estudiar elementos</td>\n      <td>no se si estudiar control</td>\n      <td>o estudiar elementos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>46</td>\n      <td>0003</td>\n      <td>Ay Si</td>\n      <td>ay si me pongo copete y ya soy emo</td>\n      <td>ay si</td>\n      <td>me pongo copete y ya soy emo</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>0012</td>\n      <td>Willy Wonka</td>\n      <td>¿conque eres regaytonero?... !!dime que se sie...</td>\n      <td>¿conque eres regaytonero?... !!</td>\n      <td>dime que se siente cagar por la boca..</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>51</td>\n      <td>0007</td>\n      <td>Futurama Fry</td>\n      <td>nO estoy seguro si nadie se levanta temprano o...</td>\n      <td>no estoy seguro si nadie se levanta temprano</td>\n      <td>o no saben que entra en el control</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPT_text(row):\n",
    "    meme_id = row.meme_id\n",
    "    text_1 = row.text_1 \n",
    "    text_2 = row.text_2 \n",
    "    return '<|'+meme_id+'|>' + text_1.strip() + ' | ' + text_2.strip()\n",
    "\n",
    "df['GPT_text'] = df.apply(GPT_text, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            GPT_text meme_id  \\\n",
       "0  <|0007|>no se si cortarme las venas | o dejarm...    0007   \n",
       "1  <|0007|>no se si estudiar control | o estudiar...    0007   \n",
       "3       <|0003|>ay si | me pongo copete y ya soy emo    0003   \n",
       "4  <|0012|>¿conque eres regaytonero?... !! | dime...    0012   \n",
       "5  <|0007|>no estoy seguro si nadie se levanta te...    0007   \n",
       "\n",
       "                                         text_1  \\\n",
       "0                   no se si cortarme las venas   \n",
       "1                     no se si estudiar control   \n",
       "3                                         ay si   \n",
       "4               ¿conque eres regaytonero?... !!   \n",
       "5  no estoy seguro si nadie se levanta temprano   \n",
       "\n",
       "                                   text_2  \n",
       "0                     o dejarmelas largas  \n",
       "1                    o estudiar elementos  \n",
       "3            me pongo copete y ya soy emo  \n",
       "4  dime que se siente cagar por la boca..  \n",
       "5      o no saben que entra en el control  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GPT_text</th>\n      <th>meme_id</th>\n      <th>text_1</th>\n      <th>text_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|0007|&gt;no se si cortarme las venas | o dejarm...</td>\n      <td>0007</td>\n      <td>no se si cortarme las venas</td>\n      <td>o dejarmelas largas</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|0007|&gt;no se si estudiar control | o estudiar...</td>\n      <td>0007</td>\n      <td>no se si estudiar control</td>\n      <td>o estudiar elementos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|0003|&gt;ay si | me pongo copete y ya soy emo</td>\n      <td>0003</td>\n      <td>ay si</td>\n      <td>me pongo copete y ya soy emo</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|0012|&gt;¿conque eres regaytonero?... !! | dime...</td>\n      <td>0012</td>\n      <td>¿conque eres regaytonero?... !!</td>\n      <td>dime que se siente cagar por la boca..</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;|0007|&gt;no estoy seguro si nadie se levanta te...</td>\n      <td>0007</td>\n      <td>no estoy seguro si nadie se levanta temprano</td>\n      <td>o no saben que entra en el control</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df[['GPT_text', 'meme_id', 'text_1', 'text_2']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_id, test_id  = train_test_split(df['GPT_text'], df['meme_id'], train_size=.9, random_state=42) # Para hacerlo estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memes en Train: 129019\nMemes en Test: 14336\n"
     ]
    }
   ],
   "source": [
    "print(f'Memes en Train: {len(train_text)}\\nMemes en Test: {len(test_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_path = '../model_data'\n",
    "\n",
    "train = os.path.join(model_data_path, 'train_trial.txt')\n",
    "test = os.path.join(model_data_path, 'test_trial.txt')\n",
    "\n",
    "with open(train, 'w') as file_handle:\n",
    "  file_handle.write(\"<|endoftext|>\".join(train_text.values.tolist()))\n",
    "\n",
    "with open(test, 'w') as file_handle:\n",
    "  file_handle.write(\"<|endoftext|>\".join(test_text.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 498M/498M [02:08<00:00, 3.88MB/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at datificate/gpt2-small-spanish.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFGPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"datificate/gpt2-small-spanish\")\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"datificate/gpt2-small-spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}