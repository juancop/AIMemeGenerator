{
 "cells": [
  {
   "source": [
    "# Separación de Datos por Frases Recurrentes\n",
    "\n",
    "El conjunto de datos que recolectamos está compuesto por textos de memes con diversas longitudes y sin una clara separación del texto que se encuentra en la parte superior e inferior de la imagen. Esto último es un problema, puesto que la división de textos es relevante para darle sentido a los memes: en el texto superior se da el contexto y en el texto inferior se da la *punchline*. \n",
    "\n",
    "En la siguiente imagen se presenta un ejemplo de un meme como lo percibe una persona y cómo lo percibe (hasta este punto) la máquina. \n",
    "<center><img src=\"resources/eg_fry.jpeg\"/></center>\n",
    "\n",
    "**Texto**: `No sé si son indirectas o solo comparte memes`\n",
    "\n",
    "Nuestro objetivo es poder dividir el texto de las plantillas en superior e inferior, utilizando reglas que describan el uso general del meme. En el caso del meme de Fry, el contexto y la *punchline* se separan por una letra **o**. De forma que dividiremos todas las plantillas utilizando esa letra. Sin embargo, existen variaciones a cada regla, por lo que es necesario tenerlas en consideración. \n",
    "\n",
    "Aquellas plantillas que no consigan dividir el texto en superior e inferior basado en las reglas, deben ser descartadas.\n",
    "\n",
    "Las reglas anteriormente mencionadas se encuentran en el archivo ``rules.json``"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Construcción de la Clase\n",
    "A continuación se construye una clase que permita implementar la lógica de selección de plantillas y división de textos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enormous-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "class splittr:\n",
    "    \"\"\"\n",
    "    Construcción de Base de Datos específica y separada\n",
    "    \"\"\"\n",
    "    \n",
    "    template_list = ['Ancient Aliens', 'Annoying Gamer Kid', 'Ay Si',\n",
    "                     'Bad Luck Brian', 'Disaster Girl', 'Filosoraptor',\n",
    "                     'Futurama Fry', 'Matias Prats', 'No me digas',\n",
    "                     'Prepare Yourself', 'Problems', 'Willy Wonka', 'Yao Wonka']\n",
    "    \n",
    "    def __init__(self, folder, json_path, rules_json):\n",
    "        self.folder = folder\n",
    "        #self.template_list = template_list\n",
    "        self.codification = self.load_json(json_path)\n",
    "        self.rules = self.load_json(rules_json)\n",
    "        self.text_field = 'texto_no_tilde'\n",
    "        self.exclude = ['Personalizado']\n",
    "        self.columns_return = ['meme_id', 'plantilla', 'texto_no_tilde', 'text_1', 'text_2']\n",
    "        \n",
    "        \n",
    "    def load_json(self, json_path):\n",
    "        \"\"\"\n",
    "        Permite la carga de un JSON que contenga los IDs de las plantillas.\n",
    "        \"\"\"\n",
    "        with open(json_path) as f:\n",
    "            json_file = json.load(f)\n",
    "        return json_file\n",
    "    \n",
    "    def load_and_transform(self):\n",
    "        file_names = os.listdir(self.folder)\n",
    "        file_paths = [os.path.join(self.folder, file) for file in file_names if ((file.find('useful') == -1) and (file.find('manual') == -1)) ]\n",
    "\n",
    "        for file_name, file_path in zip(file_names, file_paths):\n",
    "            print(f'Initialized {file_name}')\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['plantilla'] = df['plantilla'].str.strip() # Erase leading spaces\n",
    "            df = df[~df.plantilla.isin(self.exclude)] # Filters out that category\n",
    "            df['meme_id'] = df.plantilla.map(self.codification) # Applies category for model\n",
    "            df['combined_text'] = df.apply(self.row_applier, axis = 1)\n",
    "            df[['text_1', 'text_2']] = df.combined_text.str.split(',', expand = True, n = 1) # Splits Text\n",
    "\n",
    "            return_df = df[self.columns_return]\n",
    "            # Save useful observations\n",
    "            save_name_use = 'useful_' + file_name\n",
    "            save_path_use = os.path.join(self.folder, save_name_use)\n",
    "            free_of_na = return_df[(~return_df.text_1.str.contains('None')) & (~return_df.text_2.str.contains('None'))].to_csv(save_path_use)\n",
    "\n",
    "            # Save Manual Observations\n",
    "            save_name_manual = 'manual_' + file_name\n",
    "            save_path_manual = os.path.join(self.folder, save_name_manual)\n",
    "            return_df[(~return_df.meme_id.isnull()) & (return_df.text_1.str.contains('None'))].to_csv(save_path_manual)\n",
    "            print(f'Successful {file_name}')\n",
    "\n",
    "\n",
    "    def single_caracter_separator(self, text, sep, append_top = False):\n",
    "        \"\"\"\n",
    "        Implementa una función que separa en base a un sólo caracter\n",
    "        \n",
    "        Params\n",
    "        --------\n",
    "            text (str): \n",
    "                Una cadena de texto a transformar\n",
    "            \n",
    "            sep (str):\n",
    "                Una cadena de texto que separa dos frases\n",
    "            \n",
    "            append_top (bool):\n",
    "                Default = False; \n",
    "                Indica si el separador se debe incluir en la primera frase.\n",
    "                \n",
    "        Returns\n",
    "        --------\n",
    "            text_1 (str):\n",
    "                Cadena de texto de frase superior\n",
    "            \n",
    "            text_2 (str):\n",
    "                Cadena de texto de frase inferior\n",
    "        \"\"\"\n",
    "        \n",
    "        text_1, text_2 = text.split(sep)\n",
    "        if append_top:\n",
    "            text_1 += sep\n",
    "        else:\n",
    "            text_2 += sep\n",
    "            \n",
    "        return text_1, text_2\n",
    "            \n",
    "        \n",
    "    \n",
    "    def down_split(self, text, separator_list):\n",
    "        \"\"\"\n",
    "        Permite realizar la separación de forma \"down split\". \n",
    "\n",
    "        Params\n",
    "        --------\n",
    "            text (str):\n",
    "                Cadena de texto a separar\n",
    "        \n",
    "            separator_list (list):\n",
    "                Una lista que contiene todos los posibles separadores\n",
    "        \"\"\"\n",
    "        for sep in separator_list:\n",
    "            text_list = text.split(sep)\n",
    "\n",
    "            if len(text_list) == 2:\n",
    "                text_1, text_2 = text_list\n",
    "                text_2 = sep + text_2\n",
    "                return text_1, text_2\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    def top_split(self, text, separator_list):\n",
    "        \"\"\"\n",
    "        Permite realizar la separación de forma \"top split\". \n",
    "\n",
    "        Params\n",
    "        --------\n",
    "            text (str):\n",
    "                Cadena de texto a separar\n",
    "        \n",
    "            separator_list (list):\n",
    "                Una lista que contiene todos los posibles separadores\n",
    "        \"\"\"\n",
    "        for sep in separator_list:\n",
    "            text_list = text.split(sep)\n",
    "\n",
    "            if len(text_list) == 2:\n",
    "                text_1, text_2 = text_list\n",
    "                text_1 = text_1 + sep\n",
    "                return text_1, text_2\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    def row_applier(self, row):\n",
    "        \"\"\"\n",
    "        Permite aplicar una función de separación basado en reglas.\n",
    "        \"\"\"\n",
    "        text = str(row.texto_no_tilde).replace(',', '')\n",
    "        template =  ' '.join(row.plantilla.split())\n",
    "        rule = self.rules.get(template, {None: None})\n",
    "        fn = list(rule.keys())[0]\n",
    "        separators = rule.get(fn, None)\n",
    "\n",
    "        if fn == 'down_split':\n",
    "            text_1, text_2 = self.down_split(text, separators)\n",
    "        elif fn == 'top_split':\n",
    "            text_1, text_2 = self.top_split(text, separators)\n",
    "        elif fn == 'second_down_split':\n",
    "            text_1, text_2 = self.second_down_split(text, separators)\n",
    "        else:\n",
    "            text_1 = None\n",
    "            text_2 = None\n",
    "        return f'{text_1},{text_2}'\n",
    "\n",
    "    def second_down_split(self, text, separator_list):\n",
    "        \"\"\"\n",
    "        Permite realizar la separación de la segunda \"down split\". \n",
    "\n",
    "        Params\n",
    "        --------\n",
    "            text (str):\n",
    "                Cadena de texto a separar\n",
    "        \n",
    "            separator_list (list):\n",
    "                Una lista que contiene todos los posibles separadores\n",
    "        \"\"\"\n",
    "\n",
    "        for sep in separator_list:\n",
    "            text_list = text.split(sep)\n",
    "\n",
    "            if len(text_list) == 3:\n",
    "                text_1, text_2, text_3 = text_list\n",
    "                top_row = text_1 + sep + text_2\n",
    "                bot_row = sep + text_3\n",
    "                \n",
    "                return top_row, bot_row\n",
    "\n",
    "        return None, None"
   ]
  },
  {
   "source": [
    "## Utilización de la Clase\n",
    "\n",
    "En este paso se utiliza la clase splittr para generar un datset de textos que cumplen con las plantillas y su uso promedio. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9154fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = splittr(folder = '../data/bases_no_groserias', json_path = './template_id.json', rules_json = './rules.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ed6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized scrapymemes33m_no_tilde.csv\n",
      "Successful scrapymemes33m_no_tilde.csv\n",
      "Initialized scrapymemes7m_no_tilde.csv\n",
      "Successful scrapymemes7m_no_tilde.csv\n",
      "Initialized scrapymemes16m_no_tilde.csv\n",
      "Successful scrapymemes16m_no_tilde.csv\n",
      "Initialized scrapymemes32m_no_tilde.csv\n",
      "Successful scrapymemes32m_no_tilde.csv\n",
      "Initialized scrapymemes20m_no_tilde.csv\n",
      "Successful scrapymemes20m_no_tilde.csv\n",
      "Initialized scrapymemes6m_no_tilde.csv\n",
      "Successful scrapymemes6m_no_tilde.csv\n",
      "Initialized scrapymemes1m_no_tilde.csv\n",
      "Successful scrapymemes1m_no_tilde.csv\n",
      "Initialized scrapymemes24m_no_tilde.csv\n",
      "Successful scrapymemes24m_no_tilde.csv\n",
      "Initialized scrapymemes10m_no_tilde.csv\n",
      "Successful scrapymemes10m_no_tilde.csv\n",
      "Initialized scrapymemes9m_no_tilde.csv\n",
      "Successful scrapymemes9m_no_tilde.csv\n",
      "Initialized scrapymemes5m_no_tilde.csv\n",
      "Successful scrapymemes5m_no_tilde.csv\n",
      "Initialized scrapymemes8m_no_tilde.csv\n",
      "Successful scrapymemes8m_no_tilde.csv\n",
      "Initialized scrapymemes28m_no_tilde.csv\n",
      "Successful scrapymemes28m_no_tilde.csv\n",
      "Initialized scrapymemes21m_no_tilde.csv\n",
      "Successful scrapymemes21m_no_tilde.csv\n",
      "Initialized scrapymemes19m_no_tilde.csv\n",
      "Successful scrapymemes19m_no_tilde.csv\n",
      "Initialized scrapymemes15m_no_tilde.csv\n",
      "Successful scrapymemes15m_no_tilde.csv\n",
      "Initialized scrapymemes17m_no_tilde.csv\n",
      "Successful scrapymemes17m_no_tilde.csv\n",
      "Initialized scrapymemes22m_no_tilde.csv\n",
      "Successful scrapymemes22m_no_tilde.csv\n",
      "Initialized scrapymemes11m_no_tilde.csv\n",
      "Successful scrapymemes11m_no_tilde.csv\n",
      "Initialized scrapymemes18m_no_tilde.csv\n",
      "Successful scrapymemes18m_no_tilde.csv\n",
      "Initialized scrapymemes23m_no_tilde.csv\n",
      "Successful scrapymemes23m_no_tilde.csv\n",
      "Initialized scrapymemes25m_no_tilde.csv\n",
      "Successful scrapymemes25m_no_tilde.csv\n",
      "Initialized scrapymemes31m_no_tilde.csv\n",
      "Successful scrapymemes31m_no_tilde.csv\n",
      "Initialized scrapymemes13m_no_tilde.csv\n",
      "Successful scrapymemes13m_no_tilde.csv\n",
      "Initialized scrapymemes30m_no_tilde.csv\n",
      "Successful scrapymemes30m_no_tilde.csv\n",
      "Initialized scrapymemes29m_no_tilde.csv\n",
      "Successful scrapymemes29m_no_tilde.csv\n",
      "Initialized scrapymemes2mp2_no_tilde.csv\n",
      "Successful scrapymemes2mp2_no_tilde.csv\n",
      "Initialized scrapymemes14m_no_tilde.csv\n",
      "Successful scrapymemes14m_no_tilde.csv\n",
      "Initialized scrapymemes12m_no_tilde.csv\n",
      "Successful scrapymemes12m_no_tilde.csv\n",
      "Initialized scrapymemes4m_no_tilde.csv\n",
      "Successful scrapymemes4m_no_tilde.csv\n",
      "Initialized scrapymemes3m_no_tilde.csv\n",
      "Successful scrapymemes3m_no_tilde.csv\n",
      "Initialized scrapymemes26m_no_tilde.csv\n",
      "Successful scrapymemes26m_no_tilde.csv\n",
      "Initialized scrapymemes27m_no_tilde.csv\n",
      "Successful scrapymemes27m_no_tilde.csv\n",
      "Initialized scrapymemes2m_no_tilde.csv\n",
      "Successful scrapymemes2m_no_tilde.csv\n"
     ]
    }
   ],
   "source": [
    "split.load_and_transform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}